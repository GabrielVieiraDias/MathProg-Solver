<h3>Stochastic Dynamic Programming: The Risk Averse Gambler</h3>
<h4>Problem Statement</h4>
<p>
    A risk averse gambler with a stake of money enters a game with the idea
    of betting for a fixed number of rounds \(T\). With a stake \(x\) and wager
    \(u\), the resulting state is either \(x+u\) with probability \(p\), or 
    \(x-u\) with probability \(q\) (where \(p + q \leq 1\).) The wager must be
    an integer smaller than the current stake or the maximum wager established
    for the game. The total stake is limited to an amount \(N\). The gambler
    is risk averse where utility of the final stake is \(\log(x)\). Given an
    initial stake \(x < N\), calculate a strategy that maximizes the expected
    utility at the end of the game.
</p>

<h4>Formulation of a Solution</h4>
<p>
    This is a classic problem in Stochastic Dynamic Programming. The 
    function \(V(k,x)\) is the expected utility after of stake \(x\) after the 
    \(k^{th}\) wager. The expected utility satisfies the optimality equation
    \[V(k,x) = max_u [ p V(k+1,x+u) + q V(k+1,x-u) ]\] where \(V(T,x) = 
    \log(x)\). The maximization is over the set of possible bets ranging from 
    \(0\) to the minimum of \(x\), \(N-x\), or the bet limit \(B\). Note that 
    the state space and set of control actions are finite.
</p>

<h4>Solution by Linear Programming</h4>
<p>
    The optimality equation can be solved by well known methods for policy 
    iteration.  Alternatively, as shown for example by Ross in "Introduction to 
    Stochastic Dynamic Programming" (Academic Press, 1983), an exact solution can 
    be found by linear programming. We seek a solution \(V[k,x]\) minimizing
    \[\sum_{k=0}^{T-1}\sum_{x=0}^N V[k,x]\]  subject to 
    \[V[k,x] >= p V[k+1,x+u] + q V[k+1,x-u]\]
    for all feasible bets and boundary condition \(V[T,x] = \log(x)\). The set of 
    optimal wagers \(u[x]\) are found by determining the constraints that are 
    active at optimality.
</p>